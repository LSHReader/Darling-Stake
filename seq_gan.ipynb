{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"seq_gan.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"sf4M_UUlAVRJ","colab_type":"text"},"cell_type":"markdown","source":["## Google Drive Mount"]},{"metadata":{"id":"XT6fGhtQAM7z","colab_type":"code","outputId":"1a852423-e085-4e10-a4c6-57bbb1753054","executionInfo":{"status":"error","timestamp":1544288019521,"user_tz":-540,"elapsed":102896,"user":{"displayName":"김강우","photoUrl":"","userId":"13809575073066285378"}},"colab":{"base_uri":"https://localhost:8080/","height":510}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":2,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-2-10e4f377fea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mvcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"kUN0VEOMAPnK","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-mKJlCJNARV1","colab_type":"code","outputId":"dcd24fb4-6d71-4a75-c0cb-2a43a665a9c8","executionInfo":{"status":"ok","timestamp":1544254291798,"user_tz":-540,"elapsed":23249,"user":{"displayName":"김강우","photoUrl":"","userId":"13809575073066285378"}},"colab":{"base_uri":"https://localhost:8080/","height":126}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"Sk9sfgUSATFz","colab_type":"code","outputId":"f340c1fb-b3a6-4587-ef83-fcae2fab4f68","executionInfo":{"status":"ok","timestamp":1544290814359,"user_tz":-540,"elapsed":596,"user":{"displayName":"김강우","photoUrl":"","userId":"13809575073066285378"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["cd gdrive/My\\ Drive/bamboo_generator"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/bamboo_generator\n"],"name":"stdout"}]},{"metadata":{"id":"sbF1pBBvgGZO","colab_type":"code","outputId":"e14c5a92-192b-4939-c5bf-e2a39539324e","executionInfo":{"status":"ok","timestamp":1544290833070,"user_tz":-540,"elapsed":4938,"user":{"displayName":"김강우","photoUrl":"","userId":"13809575073066285378"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"cell_type":"code","source":["ls"],"execution_count":5,"outputs":[{"output_type":"stream","text":["checkpoint     experiment-log.txt    real_data.txt               train1.index\n","\u001b[0m\u001b[01;34mdefault\u001b[0m/       generator_sample.txt  \u001b[01;34mtrain1\u001b[0m/                     train1.meta\n","eval_file.txt  \u001b[01;34minput\u001b[0m/                train1.data-00000-of-00001\n"],"name":"stdout"}]},{"metadata":{"id":"i-SDhgNp_RZh","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import random\n","from dataloader import Gen_Data_loader, Dis_dataloader\n","from generator import Generator\n","from discriminator import Discriminator\n","from rollout import ROLLOUT\n","import cPickle\n","import timeit"],"execution_count":0,"outputs":[]},{"metadata":{"id":"08_3Tryl_flO","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","#########################################################################################\n","#  Generator  Hyper-parameters\n","######################################################################################\n","EMB_DIM = 100 # embedding dimension\n","HIDDEN_DIM = 32 # hidden state dimension of lstm cell\n","SEQ_LENGTH = 30 # sequence length\n","START_TOKEN = 0\n","SEED = 88\n","BATCH_SIZE = 64\n","\n","#########################################################################################\n","#  Discriminator  Hyper-parameters\n","#########################################################################################\n","dis_embedding_dim = 100\n","dis_filter_sizes = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n","dis_num_filters = [100, 200, 200, 200, 200, 100, 100, 100, 100]\n","dis_dropout_keep_prob = 0.75\n","dis_l2_reg_lambda = 0.2\n","dis_batch_size = 64\n","\n","\n","#########################################################################################\n","#  Basic Training Parameters\n","#########################################################################################\n","positive_file = 'save/input/positive_sample.txt'\n","negative_file = 'save/default/generator_sample.txt'\n","eval_file = 'save/default/eval_file.txt'\n","generated_num = 10000\n","ckpt_path = 'save/default/train1'\n","vocab_size = 30210\n","\n","#########################################################################################\n","# About an epoch\n","#########################################################################################\n","PRE_EPOCH_NUM = 1 # supervise (maximum likelihood estimation) epochs = generated\n","PRE_DIS_EPCOCH = 1 # pre-training for discriminator\n","TOTAL_BATCH = 5 # epoch for Adversaraila-Training"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fN97pqcfgazl","colab_type":"code","colab":{}},"cell_type":"code","source":["def generate_samples(sess, trainable_model, batch_size, generated_num, output_file):\n","    # Generate Samples\n","    generated_samples = []\n","    for _ in range(int(generated_num / batch_size)):\n","        generated_samples.extend(trainable_model.generate(sess))\n","\n","    with open(output_file, 'w') as fout:\n","        for poem in generated_samples:\n","            buffer = ' '.join([str(x) for x in poem]) + '\\n'\n","            fout.write(buffer)\n","\n","\n","def pre_train_epoch(sess, trainable_model, data_loader):\n","    # Pre-train the generator using MLE for one epoch\n","    supervised_g_losses = []\n","    data_loader.reset_pointer()\n","\n","    for it in xrange(data_loader.num_batch):\n","        batch = data_loader.next_batch()\n","        _, g_loss = trainable_model.pretrain_step(sess, batch)\n","        supervised_g_losses.append(g_loss)\n","\n","    return np.mean(supervised_g_losses)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0xDban88vv5i","colab_type":"code","outputId":"3e345f58-5326-48ae-a0d6-7b39eb4573a6","executionInfo":{"status":"ok","timestamp":1544257857531,"user_tz":-540,"elapsed":988612,"user":{"displayName":"김강우","photoUrl":"","userId":"13809575073066285378"}},"colab":{"base_uri":"https://localhost:8080/","height":286}},"cell_type":"code","source":["# with train_loss version\n","start = timeit.default_timer()\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","assert START_TOKEN == 0\n","\n","gen_data_loader = Gen_Data_loader(BATCH_SIZE)\n","likelihood_data_loader = Gen_Data_loader(BATCH_SIZE) # For testing\n","vocab_size = 30210\n","dis_data_loader = Dis_dataloader(BATCH_SIZE)\n","\n","generator = Generator(vocab_size, BATCH_SIZE, EMB_DIM, HIDDEN_DIM, SEQ_LENGTH, START_TOKEN)\n","\n","discriminator = Discriminator(sequence_length=SEQ_LENGTH, num_classes=2, vocab_size=vocab_size, embedding_size=dis_embedding_dim, \n","                            filter_sizes=dis_filter_sizes, num_filters=dis_num_filters, l2_reg_lambda=dis_l2_reg_lambda)\n","\n","config = tf.ConfigProto()\n","config.gpu_options.allow_growth = True\n","sess = tf.Session(config=config)\n","sess.run(tf.global_variables_initializer())\n","\n","# Get batches from positive samples \n","gen_data_loader.create_batches(positive_file)\n","\n","# Save variables\n","saver = tf.train.Saver()\n","\n","log = open('save/experiment-log.txt', 'w')\n","#  pre-train generator\n","print 'Start pre-training...'\n","log.write('pre-training...\\n')\n","for epoch in xrange(PRE_EPOCH_NUM):\n","    loss = pre_train_epoch(sess, generator, gen_data_loader)\n","    if epoch % 5 == 0:\n","        generate_samples(sess, generator, BATCH_SIZE, generated_num, eval_file)\n","        likelihood_data_loader.create_batches(eval_file)\n","\n","        print 'pre-train epoch ', epoch, 'train_loss ', loss\n","        buffer = 'epoch:\\t'+ str(epoch) + '\\tnll:\\t' + str(loss) + ' \\n'\n","        log.write(buffer)\n","\n","print 'Start pre-training discriminator...'\n","# Train 3 epoch on the generated data and do this for 50 times\n","for _ in range(PRE_DIS_EPCOCH):\n","    generate_samples(sess, generator, BATCH_SIZE, generated_num, negative_file)\n","    dis_data_loader.load_train_data(positive_file, negative_file)\n","    for _ in range(3):\n","        dis_data_loader.reset_pointer()\n","        for it in xrange(dis_data_loader.num_batch):\n","            x_batch, y_batch = dis_data_loader.next_batch()\n","            feed = {\n","                discriminator.input_x: x_batch,\n","                discriminator.input_y: y_batch,\n","                discriminator.dropout_keep_prob: dis_dropout_keep_prob\n","            }\n","            _ = sess.run(discriminator.train_op, feed)\n","\n","rollout = ROLLOUT(generator, 0.8)\n","\n","print '#########################################################################'\n","print 'Start Adversarial Training...'\n","log.write('adversarial training...\\n')\n","for total_batch in range(TOTAL_BATCH):\n","    # Train the generator for one step\n","    for it in range(1):\n","        samples = generator.generate(sess)\n","        rewards = rollout.get_reward(sess, samples, 16, discriminator)\n","        feed = {generator.x: samples, generator.rewards: rewards}\n","        train_loss, g_loss, _ = sess.run([generator.pretrain_loss, generator.g_loss, \n","                                          generator.g_updates], feed_dict=feed)\n","\n","    # Test\n","    if total_batch % 5 == 0 or total_batch == TOTAL_BATCH - 1:\n","        generate_samples(sess, generator, BATCH_SIZE, generated_num, eval_file)\n","        likelihood_data_loader.create_batches(eval_file)\n","        buffer = 'epoch:\\t' + str(total_batch) + 'NLL : ' + str(train_loss) + 'policy_loss:\\t' + str(g_loss) + ' \\n'\n","        print 'total_batch: ', total_batch, 'loss: ', g_loss\n","        log.write(buffer)\n","\n","    # Update roll-out parameters\n","    rollout.update_params()\n","\n","    # Train the discriminator\n","    for _ in range(5):\n","        generate_samples(sess, generator, BATCH_SIZE, generated_num, negative_file)\n","        dis_data_loader.load_train_data(positive_file, negative_file)\n","\n","        for _ in range(3):\n","            dis_data_loader.reset_pointer()\n","            for it in xrange(dis_data_loader.num_batch):\n","                x_batch, y_batch = dis_data_loader.next_batch()\n","                feed = {\n","                    discriminator.input_x: x_batch,\n","                    discriminator.input_y: y_batch,\n","                    discriminator.dropout_keep_prob: dis_dropout_keep_prob\n","                }\n","                _ = sess.run(discriminator.train_op, feed)\n","    saver.save(sess, ckpt_path)\n","    \n","stop = timeit.default_timer()\n","\n","print 'Time : ', stop - start"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From discriminator.py:138: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","Start pre-training...\n","pre-train epoch  0 train_loss  5.4291725\n","Start pre-training discriminator...\n","#########################################################################\n","Start Adversarial Training...\n","total_batch:  0 loss:  1422.6378\n"],"name":"stdout"}]},{"metadata":{"id":"-nRYhxMv6rsF","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}